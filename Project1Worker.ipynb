{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901e960d-2cab-4761-9621-3ba9fc7d53d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/spark\n",
      "/home/ubuntu/.local/bin/pyspark\n",
      "/usr/local/spark/python:/home/ubuntu/.local/bin/pyspark/python:\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import col, expr, translate,  trim, lower, regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer, NGram\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "import os\n",
    "print(os.environ.get('SPARK_HOME'))\n",
    "print(os.environ.get('PYSPARK_HOME'))\n",
    "print(os.environ.get('PYTHONPATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ba9d79-1b43-40ec-ad61-7fcc2a99c0b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmistune\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import unicodedata\n",
    "from pyspark import SparkContext,SparkConf,SQLContext\n",
    "from pyspark.sql import Row,SparkSession,HiveContext\n",
    "from pyspark.sql.functions import col,size,explode,split\n",
    "from pyspark.sql.types import StringType,IntegerType,ArrayType\n",
    "from pyspark.sql.functions import udf, array, length\n",
    "from bs4 import BeautifulSoup\n",
    "import mistune\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97453b82-11f7-4c75-b1ab-84c570c18452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/spark\n",
      "/usr/local/spark/python/pyspark/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get('SPARK_HOME'))  \n",
    "print(pyspark.__file__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0314a79e-c809-4857-8d94-3d3b912d69f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setAppName(\"Group1_2 Project\") \\\n",
    "    .set(\"spark.hadoop.dfs.namenode\", \"hdfs://grouop2master:9866\") \\\n",
    "    .set(\"spark.sql.warehouse.dir\", \"hdfs://grouop2master:9866/user/hive/warehouse\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c949340c-6360-488b-9807-2bd16de00fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group1_2 Project\n"
     ]
    }
   ],
   "source": [
    "if spark is not None:\n",
    "    print(spark.sparkContext.appName)  # Print the application name if it exists\n",
    "else:\n",
    "    print(\"No active SparkContext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "667d3a55-d5b4-4f87-b60f-709f8e4168e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "|            author|                body|             content|content_len|     id|      normalizedBody|           subreddit|subreddit_id|             summary|summary_len|   title|\n",
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "|  raysofdarkmatter|I think it should...|I think it should...|        178|c69al3r|I think it should...|                math|    t5_2qh0n|Shifting seasonal...|          8|    null|\n",
      "|           Stork13|Art is about the ...|Art is about the ...|        148|c6a9nxd|Art is about the ...|               funny|    t5_2qh33|Personal opinions...|          4|    null|\n",
      "|     Cloud_dreamer|Ask me what I thi...|Ask me what I thi...|         76|c6acx4l|Ask me what I thi...|         Borderlands|    t5_2r8cd|insults and slack...|         73|    null|\n",
      "|     NightlyReaper|In Mechwarrior On...|In Mechwarrior On...|        213|c8onqew|In Mechwarrior On...|            gamingpc|    t5_2sq2y|Yes, Joysticks in...|         19|    null|\n",
      "|    NuffZetPand0ra|You are talking a...|You are talking a...|        404|c6acxvc|You are talking a...|              Diablo|    t5_2qore|Class only items ...|          7|D2 help?|\n",
      "|beatlecreedcabaret|All but one of my...|All but one of my...|        130|c6ahuc4|All but one of my...|   RedditLaqueristas|    t5_2se5q|      OPI Nail Envy!|          3|    null|\n",
      "|      nobodysdiary|I could give a sh...|I could give a sh...|        156|c6aggux|I could give a sh...|               apple|    t5_2qh1f|I don't drive lik...|         18|    null|\n",
      "|          chrom_ed|So you're saying ...|So you're saying ...|        134|c6agxtv|So you're saying ...|               apple|    t5_2qh1f|you don't seem to...|          9|    null|\n",
      "|      gadzookfilms|I love this idea ...|I love this idea ...|        126|c6asb7p|I love this idea ...|RedditFilmsProduc...|    t5_2v33h|How we make money...|          9|    null|\n",
      "|      iamacannibal|Theres an entire ...|Theres an entire ...|        181|c6aveyw|Theres an entire ...|       AbandonedPorn|    t5_2sh6t|I'll try and get ...|         25|    null|\n",
      "| splagaticusxoxo97|FALSE. Evidence: ...|FALSE. Evidence: ...|        124|c6bacqq|FALSE. Evidence: ...|             atheism|    t5_2qh2p|dont fuck with re...|          6|    null|\n",
      "|           orthzar|If the number of ...|If the number of ...|         12|c6b83kp|If the number of ...|              quotes|    t5_2qhdx|                  no|          1|    null|\n",
      "|          phyzishy|Yeah, but most fo...|Yeah, but most fo...|         75|c6b52m8|Yeah, but most fo...|           AskReddit|    t5_2qh1i|       stupid stuff.|          2|    null|\n",
      "|          Wheelman|As an entrepreneu...|As an entrepreneu...|         78|c6b34c2|As an entrepreneu...|     personalfinance|    t5_2qstm|get a good CPA - ...|         14|    null|\n",
      "|        slagahthor|i guess the way I...|i guess the way I...|        323|c6b9gqo|i guess the way I...|             Animals|    t5_2qi0c|Dog neglected for...|          7|    null|\n",
      "|        Perservere|Didn't they lose ...|Didn't they lose ...|         86|c6bftvc|Didn't they lose ...|     leagueoflegends|    t5_2rfxx|just because you'...|         23|    null|\n",
      "|       fallsuspect|You probably won'...|You probably won'...|         79|c6bncqn|You probably won'...|           AskReddit|    t5_2qh1i|just get both of ...|         11|    null|\n",
      "|          captain0|To simply say tha...|To simply say tha...|        328|c6btcx4|To simply say tha...|              videos|    t5_2qh1e| Oppan Gangnam Style|          3|    null|\n",
      "|    Buck_Speedjunk|This picture does...|This picture does...|         18|c6c4uks|This picture does...|               trees|    t5_2r9vp|It's a half-assed...|         13|    null|\n",
      "|        FrankManic|And that is, hand...|And that is, hand...|         57|c6c7pgn|And that is, hand...|               Games|    t5_2qhwp|Play balance is f...|         13|    null|\n",
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hdfs_path = \"hdfs://grouop2master:9000//user/ubuntu/corpus-webis-tldr-17.json\" \n",
    "df = spark.read.json(hdfs_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5505b53-3004-4941-8601-92c0fa1874be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|           subreddit|\n",
      "+--------------------+--------------------+\n",
      "|I think it should...|                math|\n",
      "|Art is about the ...|               funny|\n",
      "|Ask me what I thi...|         Borderlands|\n",
      "|In Mechwarrior On...|            gamingpc|\n",
      "|You are talking a...|              Diablo|\n",
      "|All but one of my...|   RedditLaqueristas|\n",
      "|I could give a sh...|               apple|\n",
      "|So you're saying ...|               apple|\n",
      "|I love this idea ...|RedditFilmsProduc...|\n",
      "|Theres an entire ...|       AbandonedPorn|\n",
      "|FALSE. Evidence: ...|             atheism|\n",
      "|If the number of ...|              quotes|\n",
      "|Yeah, but most fo...|           AskReddit|\n",
      "|As an entrepreneu...|     personalfinance|\n",
      "|i guess the way I...|             Animals|\n",
      "|Didn't they lose ...|     leagueoflegends|\n",
      "|You probably won'...|           AskReddit|\n",
      "|To simply say tha...|              videos|\n",
      "|This picture does...|               trees|\n",
      "|And that is, hand...|               Games|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\"body\", \"subreddit\")  \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1ebf94-38ed-4f9c-9e7b-06d66dd8f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|           subreddit|\n",
      "+--------------------+--------------------+\n",
      "|I think it should...|                math|\n",
      "|Art is about the ...|               funny|\n",
      "|Ask me what I thi...|         borderlands|\n",
      "|In Mechwarrior On...|            gamingpc|\n",
      "|You are talking a...|              diablo|\n",
      "|All but one of my...|   redditlaqueristas|\n",
      "|I could give a sh...|               apple|\n",
      "|So you're saying ...|               apple|\n",
      "|I love this idea ...|redditfilmsproduc...|\n",
      "|Theres an entire ...|       abandonedporn|\n",
      "|FALSE. Evidence: ...|             atheism|\n",
      "|If the number of ...|              quotes|\n",
      "|Yeah, but most fo...|           askreddit|\n",
      "|As an entrepreneu...|     personalfinance|\n",
      "|i guess the way I...|             animals|\n",
      "|Didn't they lose ...|     leagueoflegends|\n",
      "|You probably won'...|           askreddit|\n",
      "|To simply say tha...|              videos|\n",
      "|This picture does...|               trees|\n",
      "|And that is, hand...|               games|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"subreddit\", lower(df[\"subreddit\"]))# convert subreddit categories to lowercase\n",
    "df = df.withColumn(\"subreddit\", trim(\"subreddit\"))# remove white spaces in subreddit\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b6c335-c647-471f-a074-df137741c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|           subreddit|\n",
      "+--------------------+--------------------+\n",
      "|I think it should...|                math|\n",
      "|Art is about the ...|               funny|\n",
      "|Ask me what I thi...|         borderlands|\n",
      "|In Mechwarrior On...|            gamingpc|\n",
      "|You are talking a...|              diablo|\n",
      "|All but one of my...|   redditlaqueristas|\n",
      "|I could give a sh...|               apple|\n",
      "|So youre saying t...|               apple|\n",
      "|I love this idea ...|redditfilmsproduc...|\n",
      "|Theres an entire ...|       abandonedporn|\n",
      "|FALSE Evidence Wo...|             atheism|\n",
      "|If the number of ...|              quotes|\n",
      "|Yeah but most fol...|           askreddit|\n",
      "|As an entrepreneu...|     personalfinance|\n",
      "|i guess the way I...|             animals|\n",
      "|Didnt they lose  ...|     leagueoflegends|\n",
      "|You probably wont...|           askreddit|\n",
      "|To simply say tha...|              videos|\n",
      "|This picture does...|               trees|\n",
      "|And that is hands...|               games|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('body', translate('body', '1234567890!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~', ' '))# remove punctuation and numbers in the body column\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68efc7f2-6c5d-4179-962d-f9c88ea5a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|           subreddit|\n",
      "+--------------------+--------------------+\n",
      "|I think it should...|                math|\n",
      "|Art is about the ...|               funny|\n",
      "|Ask me what I thi...|         borderlands|\n",
      "|In Mechwarrior On...|            gamingpc|\n",
      "|You are talking a...|              diablo|\n",
      "|All but one of my...|   redditlaqueristas|\n",
      "|I could give a sh...|               apple|\n",
      "|So youre saying t...|               apple|\n",
      "|I love this idea ...|redditfilmsproduc...|\n",
      "|Theres an entire ...|       abandonedporn|\n",
      "|FALSE Evidence Wo...|             atheism|\n",
      "|If the number of ...|              quotes|\n",
      "|Yeah but most fol...|           askreddit|\n",
      "|As an entrepreneu...|     personalfinance|\n",
      "|i guess the way I...|             animals|\n",
      "|Didnt they lose g...|     leagueoflegends|\n",
      "|You probably wont...|           askreddit|\n",
      "|To simply say tha...|              videos|\n",
      "|This picture does...|               trees|\n",
      "|And that is hands...|               games|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"body\", regexp_replace(col(\"body\"), \"\\\\s+\", \" \"))#remove white spaces in body\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dfe09bb-18a7-4cee-ad30-ddb83ebbf7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|           subreddit|\n",
      "+--------------------+--------------------+\n",
      "|I think it should...|                math|\n",
      "|Art is about the ...|               funny|\n",
      "|Ask me what I thi...|         borderlands|\n",
      "|In Mechwarrior On...|            gamingpc|\n",
      "|You are talking a...|              diablo|\n",
      "|All but one of my...|   redditlaqueristas|\n",
      "|I could give a sh...|               apple|\n",
      "|So youre saying t...|               apple|\n",
      "|I love this idea ...|redditfilmsproduc...|\n",
      "|Theres an entire ...|       abandonedporn|\n",
      "|FALSE Evidence Wo...|             atheism|\n",
      "|If the number of ...|              quotes|\n",
      "|Yeah but most fol...|           askreddit|\n",
      "|As an entrepreneu...|     personalfinance|\n",
      "|i guess the way I...|             animals|\n",
      "|Didnt they lose g...|     leagueoflegends|\n",
      "|You probably wont...|           askreddit|\n",
      "|To simply say tha...|              videos|\n",
      "|This picture does...|               trees|\n",
      "|And that is hands...|               games|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.filter(df.body != '')# delete empty lines\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae4cd491-03e9-47cd-ad98-2339a2862287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                body|           subreddit|               words|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|I think it should...|                math|[i, think, it, sh...|\n",
      "|Art is about the ...|               funny|[art, is, about, ...|\n",
      "|Ask me what I thi...|         borderlands|[ask, me, what, i...|\n",
      "|In Mechwarrior On...|            gamingpc|[in, mechwarrior,...|\n",
      "|You are talking a...|              diablo|[you, are, talkin...|\n",
      "|All but one of my...|   redditlaqueristas|[all, but, one, o...|\n",
      "|I could give a sh...|               apple|[i, could, give, ...|\n",
      "|So youre saying t...|               apple|[so, youre, sayin...|\n",
      "|I love this idea ...|redditfilmsproduc...|[i, love, this, i...|\n",
      "|Theres an entire ...|       abandonedporn|[theres, an, enti...|\n",
      "|FALSE Evidence Wo...|             atheism|[false, evidence,...|\n",
      "|If the number of ...|              quotes|[if, the, number,...|\n",
      "|Yeah but most fol...|           askreddit|[yeah, but, most,...|\n",
      "|As an entrepreneu...|     personalfinance|[as, an, entrepre...|\n",
      "|i guess the way I...|             animals|[i, guess, the, w...|\n",
      "|Didnt they lose g...|     leagueoflegends|[didnt, they, los...|\n",
      "|You probably wont...|           askreddit|[you, probably, w...|\n",
      "|To simply say tha...|              videos|[to, simply, say,...|\n",
      "|This picture does...|               trees|[this, picture, d...|\n",
      "|And that is hands...|               games|[and, that, is, h...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "df = tokenizer.transform(df)# split each sentence into separate words\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c22f3678-d9c0-4705-8e87-5d123cf65516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                body|           subreddit|               words|      filtered_words|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|I think it should...|                math|[i, think, it, sh...|[think, fixed, ei...|\n",
      "|Art is about the ...|               funny|[art, is, about, ...|[art, hardest, th...|\n",
      "|Ask me what I thi...|         borderlands|[ask, me, what, i...|[ask, think, wall...|\n",
      "|In Mechwarrior On...|            gamingpc|[in, mechwarrior,...|[mechwarrior, onl...|\n",
      "|You are talking a...|              diablo|[you, are, talkin...|[talking, charsi,...|\n",
      "|All but one of my...|   redditlaqueristas|[all, but, one, o...|[one, nails, ball...|\n",
      "|I could give a sh...|               apple|[i, could, give, ...|[give, shit, turn...|\n",
      "|So youre saying t...|               apple|[so, youre, sayin...|[youre, saying, t...|\n",
      "|I love this idea ...|redditfilmsproduc...|[i, love, this, i...|[love, idea, defi...|\n",
      "|Theres an entire ...|       abandonedporn|[theres, an, enti...|[theres, entire, ...|\n",
      "|FALSE Evidence Wo...|             atheism|[false, evidence,...|[false, evidence,...|\n",
      "|If the number of ...|              quotes|[if, the, number,...|[number, sides, c...|\n",
      "|Yeah but most fol...|           askreddit|[yeah, but, most,...|[yeah, folks, thi...|\n",
      "|As an entrepreneu...|     personalfinance|[as, an, entrepre...|[entrepreneurfree...|\n",
      "|i guess the way I...|             animals|[i, guess, the, w...|[guess, way, tell...|\n",
      "|Didnt they lose g...|     leagueoflegends|[didnt, they, los...|[didnt, lose, gam...|\n",
      "|You probably wont...|           askreddit|[you, probably, w...|[probably, wont, ...|\n",
      "|To simply say tha...|              videos|[to, simply, say,...|[simply, say, mas...|\n",
      "|This picture does...|               trees|[this, picture, d...|[picture, doesnt,...|\n",
      "|And that is hands...|               games|[and, that, is, h...|[hands, coolest, ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "df = stopwords_remover.transform(df) # remove stopwords\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80ff884a-3444-42bc-9316-4a74cb9f1b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------------+--------------+\n",
      "|           subreddit|total_word_count|other_word_count|sentence_count|\n",
      "+--------------------+----------------+----------------+--------------+\n",
      "|               anime|         1565594|          806284|          5868|\n",
      "|              travel|          885554|          447319|          3076|\n",
      "|londonfootballmeetup|            1802|             888|             6|\n",
      "|     youtubecomments|            1303|             698|             8|\n",
      "|                cubs|           21827|           11318|            85|\n",
      "|              poetry|           64591|           32451|           220|\n",
      "|                tmnt|           20841|           10652|            54|\n",
      "|      dippingtobacco|           53285|           26489|           289|\n",
      "|       crohnsdisease|          193440|           95665|           594|\n",
      "|           metro2033|            1967|            1068|            16|\n",
      "|             marxism|            1822|             958|            10|\n",
      "|        marvelheroes|          102752|           53774|           416|\n",
      "|                 art|          160596|           79984|           688|\n",
      "|               mcnsa|            8273|            4234|            39|\n",
      "|          costa_rica|            9621|            4871|            31|\n",
      "|             4runner|            6416|            3331|            26|\n",
      "|             jewelry|           20265|           10236|            74|\n",
      "|         battlefront|           10925|            5677|            29|\n",
      "|          lifeguards|           13772|            6652|            40|\n",
      "|            lacrosse|           45306|           22968|           246|\n",
      "+--------------------+----------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = df.groupBy(\"subreddit\").agg(\n",
    "    F.sum(F.size(\"words\")).alias(\"total_word_count\"),#calculate the number of all words in each subreddit category\n",
    "    F.sum(F.size(\"filtered_words\")).alias(\"other_word_count\"),#calculate the number of words after removing stop words in each subreddit category\n",
    "    F.count(\"body\").alias(\"sentence_count\")#calculate the number of requests in each subreddit category\n",
    ")\n",
    "\n",
    "result.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e94af612-f202-4350-9254-1ef341216344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:====================================================> (194 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+----------------+--------------+\n",
      "|subreddit          |total_word_count|other_word_count|sentence_count|\n",
      "+-------------------+----------------+----------------+--------------+\n",
      "|askreddit          |145463239       |70295937        |589947        |\n",
      "|relationships      |173638495       |78013133        |352049        |\n",
      "|leagueoflegends    |25763882        |13366879        |109307        |\n",
      "|tifu               |19268244        |9257272         |52219         |\n",
      "|relationship_advice|24645327        |11050084        |50416         |\n",
      "|trees              |11815990        |5747224         |47286         |\n",
      "|gaming             |9176368         |4696013         |43851         |\n",
      "|atheism            |11621663        |5666301         |43268         |\n",
      "|adviceanimals      |7872130         |3883801         |40783         |\n",
      "|funny              |6947389         |3497120         |40171         |\n",
      "|politics           |8614353         |4429484         |36518         |\n",
      "|pics               |6011709         |3032386         |35098         |\n",
      "|sex                |9072066         |4231503         |28806         |\n",
      "|wtf                |4713252         |2363365         |25781         |\n",
      "|explainlikeimfive  |6169612         |3186121         |25482         |\n",
      "|todayilearned      |4767997         |2456907         |25004         |\n",
      "|fitness            |5236232         |2706154         |22694         |\n",
      "|iama               |5548844         |2738448         |22689         |\n",
      "|worldnews          |4925650         |2549791         |22577         |\n",
      "|dota2              |5363116         |2817158         |22405         |\n",
      "+-------------------+----------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "popular_subreddit= result.orderBy(col(\"sentence_count\").desc())# find the most popular category\n",
    "popular_subreddit.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd9748-18fe-499f-bc44-cb07d0ec60f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2635e636-802a-4739-8448-79a404ae86f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`stop_word_percentage`' given input columns: [other_word_count, sentence_count, subreddit, total_word_count];;\n'Sort ['stop_word_percentage DESC NULLS LAST], true\n+- Filter (sentence_count#268L > cast(10 as bigint))\n   +- Aggregate [subreddit#101], [subreddit#101, sum(cast(size(words#156, true) as bigint)) AS total_word_count#264L, sum(cast(size(filtered_words#177, true) as bigint)) AS other_word_count#266L, count(body#129) AS sentence_count#268L]\n      +- Project [body#129, subreddit#101, words#156, UDF(words#156) AS filtered_words#177]\n         +- Project [body#129, subreddit#101, UDF(body#129) AS words#156]\n            +- Filter NOT (body#129 = )\n               +- Project [regexp_replace(body#115, \\s+,  ) AS body#129, subreddit#101]\n                  +- Project [translate(body#8, 1234567890!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~,  ) AS body#115, subreddit#101]\n                     +- Project [body#8, trim(subreddit#98, None) AS subreddit#101]\n                        +- Project [body#8, lower(subreddit#13) AS subreddit#98]\n                           +- Project [body#8, subreddit#13]\n                              +- Relation[author#7,body#8,content#9,content_len#10L,id#11,normalizedBody#12,subreddit#13,subreddit_id#14,summary#15,summary_len#16L,title#17] json\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m most_popular_subredits \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mfilter(result\u001b[38;5;241m.\u001b[39msentence_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m)\u001b[38;5;66;03m# display the category, where the percentage of stopwords is the highest and the number of requests is more than 10\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmost_popular_subredits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morderBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_word_percentage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1195\u001b[0m, in \u001b[0;36mDataFrame.sort\u001b[0;34m(self, *cols, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;129m@ignore_unicode_prefix\u001b[39m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;129m@since\u001b[39m(\u001b[38;5;241m1.3\u001b[39m)\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msort\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a new :class:`DataFrame` sorted by the specified column(s).\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03m    :param cols: list of :class:`Column` or column names to sort by.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    [Row(age=5, name=u'Bob'), Row(age=2, name=u'Alice')]\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1195\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort_cols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:134\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    130\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`stop_word_percentage`' given input columns: [other_word_count, sentence_count, subreddit, total_word_count];;\n'Sort ['stop_word_percentage DESC NULLS LAST], true\n+- Filter (sentence_count#268L > cast(10 as bigint))\n   +- Aggregate [subreddit#101], [subreddit#101, sum(cast(size(words#156, true) as bigint)) AS total_word_count#264L, sum(cast(size(filtered_words#177, true) as bigint)) AS other_word_count#266L, count(body#129) AS sentence_count#268L]\n      +- Project [body#129, subreddit#101, words#156, UDF(words#156) AS filtered_words#177]\n         +- Project [body#129, subreddit#101, UDF(body#129) AS words#156]\n            +- Filter NOT (body#129 = )\n               +- Project [regexp_replace(body#115, \\s+,  ) AS body#129, subreddit#101]\n                  +- Project [translate(body#8, 1234567890!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~,  ) AS body#115, subreddit#101]\n                     +- Project [body#8, trim(subreddit#98, None) AS subreddit#101]\n                        +- Project [body#8, lower(subreddit#13) AS subreddit#98]\n                           +- Project [body#8, subreddit#13]\n                              +- Relation[author#7,body#8,content#9,content_len#10L,id#11,normalizedBody#12,subreddit#13,subreddit_id#14,summary#15,summary_len#16L,title#17] json\n"
     ]
    }
   ],
   "source": [
    "most_popular_subredits = result.filter(result.sentence_count > 10)# display the category, where the percentage of stopwords is the highest and the number of requests is more than 10\n",
    "most_popular_subredits.orderBy(col(\"stop_word_percentage\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ffe0f06-e68c-4904-b931-f5ddd919a84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             ngrams2|\n",
      "+--------------------+\n",
      "|[i think, think i...|\n",
      "|[art is, is about...|\n",
      "|[ask me, me what,...|\n",
      "|[in mechwarrior, ...|\n",
      "|[you are, are tal...|\n",
      "|[all but, but one...|\n",
      "|[i could, could g...|\n",
      "|[so youre, youre ...|\n",
      "|[i love, love thi...|\n",
      "|[theres an, an en...|\n",
      "|[false evidence, ...|\n",
      "|[if the, the numb...|\n",
      "|[yeah but, but mo...|\n",
      "|[as an, an entrep...|\n",
      "|[i guess, guess t...|\n",
      "|[didnt they, they...|\n",
      "|[you probably, pr...|\n",
      "|[to simply, simpl...|\n",
      "|[this picture, pi...|\n",
      "|[and that, that i...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = NGram(n=2, inputCol=\"words\", outputCol=\"ngrams2\")# ngram calculation where n=2\n",
    "df = ngram.transform(df)\n",
    "df.select(\"ngrams2\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a13cf68e-4d17-44f3-a9fe-85f5cac94729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(pair2='of the', count=3478162)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  pair2|  count|\n",
      "+-------+-------+\n",
      "| of the|3478162|\n",
      "| in the|3389036|\n",
      "|  and i|2871662|\n",
      "|  i was|2865442|\n",
      "|  to be|2200242|\n",
      "| to the|2013867|\n",
      "| i have|1898029|\n",
      "| on the|1744995|\n",
      "| that i|1665249|\n",
      "| i dont|1658424|\n",
      "|  but i|1568086|\n",
      "| it was|1517470|\n",
      "|want to|1502303|\n",
      "|   i am|1461029|\n",
      "|for the|1420812|\n",
      "|   in a|1403413|\n",
      "|  for a|1313219|\n",
      "|   so i|1284937|\n",
      "| to get|1263131|\n",
      "| if you|1158753|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_pairs_df = df.select(F.explode(\"ngrams2\").alias(\"pair2\"))# transform each pair into a separate row\n",
    "pair_counts = all_pairs_df.groupBy(\"pair2\").count()# count the number of pairs\n",
    "most_common_word_pair = pair_counts.orderBy(F.desc(\"count\")).first()\n",
    "print(most_common_word_pair)# print the most popular pair\n",
    "pair_counts.orderBy(F.desc(\"count\")).show()# print first 20 popular pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edbf4405-8de5-4408-a272-b9bb36449edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              ngrams|\n",
      "+--------------------+\n",
      "|[i think it, thin...|\n",
      "|[art is about, is...|\n",
      "|[ask me what, me ...|\n",
      "|[in mechwarrior o...|\n",
      "|[you are talking,...|\n",
      "|[all but one, but...|\n",
      "|[i could give, co...|\n",
      "|[so youre saying,...|\n",
      "|[i love this, lov...|\n",
      "|[theres an entire...|\n",
      "|[false evidence w...|\n",
      "|[if the number, t...|\n",
      "|[yeah but most, b...|\n",
      "|[as an entreprene...|\n",
      "|[i guess the, gue...|\n",
      "|[didnt they lose,...|\n",
      "|[you probably won...|\n",
      "|[to simply say, s...|\n",
      "|[this picture doe...|\n",
      "|[and that is, tha...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = NGram(n=3, inputCol=\"words\", outputCol=\"ngrams\")# ngram calculation where n=3\n",
    "df = ngram.transform(df)\n",
    "df.select(\"ngrams\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ff472-dc26-4ed8-bb27-e06d907ed8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs_df = df.select(F.explode(\"ngrams\").alias(\"pair\"))# transform each pair into a separate row\n",
    "pair_counts = all_pairs_df.groupBy(\"pair\").count()# count the number of pairs\n",
    "most_common_word_pair = pair_counts.orderBy(F.desc(\"count\")).first()\n",
    "print(most_common_word_pair)# print the most popular pair\n",
    "pair_counts.orderBy(F.desc(\"count\")).show()# print first 20 popular pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593444a-0047-4f01-9fd9-b90f20133b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
